---
title: "Standard architectures"
---

Always On architectures for Postgres reflect EDB’s recommended practices and help you to achieve the highest possible service availability in multiple configurations. These configurations range from single-location architectures to complex distributed systems that protect from hardware failures and data center failures. The architectures leverage EDB Postgres Distributed’s multi-master capability and its ability to achieve 99.999% availability, even during maintenance operations.

You can use EDB Postgres Distributed for architectures beyond the examples described here. Use-case-specific variations have been successfully deployed in production. However, these variations must undergo rigorous architecture review first. Also, EDB’s standard deployment tool for Always On architectures, TPAExec, must be enabled to support the variations before they can be supported in production environments.

For additional information, see [EDB Postgres Distributed: The Next Generation of PostgreSQL High Availability](https://info.enterprisedb.com/WhitePaperPostgres-BDRTheNextGenerationofPostgreSQLHighAvailability.html?_ga=2.95771928.561267847.1631518032-2107066053.1628865149) and [The End of the Reign of Oracle RAC: EDB Postgres Distributed Always On](https://info.enterprisedb.com/White_Paper_The_End_of_the_Reign_of_OracleRAC_Postgres-BDR_Always_On.html?_ga=2.95771928.561267847.1631518032-2107066053.1628865149).

## Standard EDB Always On architectures

EDB has identified four standard architectures:

-  Always On Bronze: Single active location (data center or availability zone \[AZ\])
-  Always On Silver: Single active location with redundant hardware to quickly restore failover capability and a backup in a disaster recovery (DR) location
-  Always On Gold: Two active locations
-  Always On Platinum: Two active locations with additional redundant hardware in a hot standby mode

All Always On architectures protect a progressively robust range of failure situations. For example, Always On Bronze protects against local hardware failure but doesn't provide protection from location (data center or AZ) failure. Always On Silver makes sure that a backup is kept at a different location, thus providing some protection in case of the catastrophic loss of a location. However, the database still must be restored from backup first, which might violate recovery time objective (RTO) requirements. Always On Gold provides two active locations connected in a multi-master mesh network, making sure that service remains available even in case a location goes offline. Finally, Always On Platinum adds redundant hot standby hardware in both locations to maintain local high availability in case of a hardware failure.

Each architecture can provide zero recovery point objective (RPO), as data can be streamed synchronously to at least one local master, thus guaranteeing zero data loss in case of local hardware failure.

Increasing the availability guarantee drives additional cost for hardware and licenses, networking requirements, and operational complexity. Carefully consider your availability and compliance requirements before choosing an architecture.

## Architecture details

EDB Postgres Distributed uses a [Raft](https://raft.github.io)-based consensus architecture. While regular database operations (insert, select, delete) don’t require cluster-wide consensus, EDB Postgres Distributed benefits from an odd number of BDR nodes to make decisions that require consensus, such as generating new global sequences, or distributed DDL operations. Even the simpler architectures always have three BDR nodes, even if not all of them are storing data. Always On Gold and Platinum, which use two active locations, introduce a fifth BDR node as a witness node to support the RAFT requirements.

Applications connect to the standard Always On architectures by way of multi-host connection strings, where each pgBouncer/HAProxy server is a distinct entry in the multi-host connection string. Other connection mechanisms have been successfully deployed in production, but they're not part of the standard Always On architectures.

### Always On Bronze (single active location)

The Always On Bronze architecture includes the following:

-  Three BDR nodes; one is a witness only and doesn't hold data
-  Barman node for backup and recovery can be offsite
-  Two pgBouncer/HAProxy nodes

BDR nodes can also be spread across availability zones.

![Always On Bronze architecture](../images/bronze.png)

### Always On Silver (single active location, backup in DR location) 

The Always On Silver architecture includes the following:

-  Three BDR nodes; each node has data
-  Redundant hardware to quickly restore failover capability
-  Barman offsite (offsite is optional but recommended)
-  Two pgBouncer/HAProxy nodes

BDR nodes can also be spread across AZs, and Barman can be located in location A.

![Always On Silver architecture](../images/silver.png)

### Always On Gold (two active locations)

The Always On Silver architecture includes the following:

-  Four BDR nodes (two in location A, two in location B)
-  Two Barman nodes (one in location A, one in location B)
-  One witness node in location C (optional but recommended)
-  Four pgBouncer/HAProxy Nodes (two in location A, two in location B)

![Always On Gold architecture](../images/gold.png)

### Always On Platinum (two locations; fast HA restoration)

The Always On Platinum architecture includes the following:

-  Four BDR nodes (two in location A, two in location B)
-  Two logical standbys (one in location A, one in location B)
-  Two Barman nodes (one in location A, one in location B)
-  One witness node in location C (optional but recommended)
-  4 pgBouncer/HAProxy Nodes (2 in location A, two in location B)

Both locations have redundant hot standby hardware to maintain local high availability in case of a hardware failure without waiting to restore a BDR node from backup.

![Always On Platinum architecture](../images/platinum.png)

## Choosing the right architecture

Use these criteria to help you to select the appropriate Always On architecture.

|                             | Always On Bronze | Always On Silver | Always On Gold | Always On - Platinum |
|-----------------------------|------------------|------------------|----------------|----------------------|
| Hardware failure protection | Yes              | Yes              | Yes            | Yes                  |
| Location failure protection | No (unless Barman is moved offsite)| Yes - Recovery from backup | Yes - instant failover to fully functional site | Yes - instant failover to fully functional site |
| Failover to DR or full DC   | DR (if Barman is located offsite); NA otherwise | DR (if Barman is located offsite) | Full DC | Full DC |
| Zero downtime upgrade       | Yes              | Yes              | Yes            | Yes                  |
| Support of availability zones in public/ private cloud | Yes  | Yes              | Yes            | Yes                  |
| Fast local restoration of high availability after device failure | No; time to restore HA: (1) VM prov + (2) approx 60 min/500GB | Yes; three local BDR nodes allow to maintain HA after device failure | No; time to restore HA: (1) VM prov + (2) approx 60 min/500GB | Yes; logical standbys can quickly be promoted to full BDR nodes |
| Cross data center network traffic | Backup traffic only (if Barman is located offsite); none otherwise | Backup traffic only (if Barman is located offsite); none otherwise | Full replication traffic | Full replication traffic |
| BDR license cost            | 2 BDR nodes      | 3 BDR nodes      | 4 BDR nodes     | 4 BDR nodes <br/>2 logical standbys |

## Deployment and sizing considerations

For production deployments, EDB recommends a minimum of 12 cores for each BDR server and logical standbys. Witness nodes don't participate in the data replication operation and don't have to meet this requirement. Always size logical standbys exactly like the BDR nodes to avoid performance degradations in case of a node promotion. In production deployments, pgBouncer/HAProxy nodes require a minimum of four cores, with a minimum of two cores being assigned to pgBouncer and HAProxy each. EDB recommends detailed benchmarking of performance requirements, working with EDB’s Professional Services team.

For development purposes, don't assign BDR nodes fewer than two cores. The sizing of Barman nodes depends on the database size and the data change rate.

You can deploy BDR nodes, logical standbys, Barman nodes, and pgBouncer/HAProxy nodes on virtual machines or in a bare metal deployment mode. However, maintain anti-affinity between BDR nodes and pgBouncer/HAProxy nodes.
Don't co-locate multiple BDR nodes on VMs that are on the same physical hardware, as that reduces resilience.
Also don't co-locate multiple pgBouncer/HAProxy nodes on VMs on the same physical hardware, as that, too, reduces resilience. 

You can co-locate single pgBouncer/HAProxy nodes with single BDR nodes when deployed as VMs.

When pgBouncer/HAProxy nodes are co-located with BDR nodes, use separate VMs to ensure proper CPU and memory resource assignment.
